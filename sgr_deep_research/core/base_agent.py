import json
import logging
import os
import traceback
import uuid
from datetime import datetime
from typing import Type

from openai import AsyncOpenAI
from openai.types.chat import ChatCompletionFunctionToolParam

from sgr_deep_research.core.agent_definition import ExecutionConfig, LLMConfig, PromptsConfig
from sgr_deep_research.core.models import AgentStatesEnum, ResearchContext
from sgr_deep_research.core.services.prompt_loader import PromptLoader
from sgr_deep_research.core.services.registry import AgentRegistry
from sgr_deep_research.core.stream import OpenAIStreamingGenerator
from sgr_deep_research.core.tools import (
    BaseTool,
    ClarificationTool,
    ReasoningTool,
    WebSearchTool,
    ExtractPageContentTool,
    GeneratePlanTool,
    AdaptPlanTool,
    CreateReportTool,
    FinalAnswerTool,
)


class AgentRegistryMixin:
    def __init_subclass__(cls, **kwargs):
        super().__init_subclass__(**kwargs)
        if cls.__name__ not in ("BaseAgent",):
            AgentRegistry.register(cls, name=cls.name)


class BaseAgent(AgentRegistryMixin):
    """Base class for agents."""

    name: str = "base_agent"

    def __init__(
        self,
        task: str,
        openai_client: AsyncOpenAI,
        llm_config: LLMConfig,
        prompts_config: PromptsConfig,
        execution_config: ExecutionConfig,
        toolkit: list[Type[BaseTool]] | None = None,
        **kwargs: dict,
    ):
        self.id = f"{self.name}_{uuid.uuid4()}"
        self.logger = logging.getLogger(f"sgr_deep_research.agents.{self.id}")
        self.creation_time = datetime.now()
        self.task = task
        self.toolkit = toolkit or []

        self._context = ResearchContext()
        self.conversation = []
        self.log = []
        self.max_iterations = execution_config.max_iterations
        self.max_clarifications = execution_config.max_clarifications

        self.openai_client = openai_client
        self.llm_config = llm_config
        self.prompts_config = prompts_config

        self.streaming_generator = OpenAIStreamingGenerator(model=self.id)

    async def provide_clarification(self, clarifications: str):
        """Receive clarification from external source (e.g. user input)"""
        self.conversation.append(
            {"role": "user", "content": PromptLoader.get_clarification_template(clarifications, self.prompts_config)}
        )
        self._context.clarifications_used += 1
        self._context.clarification_received.set()
        self._context.state = AgentStatesEnum.RESEARCHING
        self.logger.info(f"âœ… Clarification received: {clarifications[:2000]}...")

    def _log_reasoning(self, result: ReasoningTool) -> None:
        next_step = result.remaining_steps[0] if result.remaining_steps else "Completing"
        self.logger.info(
            f"""
    ###############################################
    ðŸ¤– LLM RESPONSE DEBUG:
       ðŸ§  Reasoning Steps: {result.reasoning_steps}
       ðŸ“Š Current Situation: '{result.current_situation[:400]}...'
       ðŸ“‹ Plan Status: '{result.plan_status[:400]}...'
       ðŸ” Searches Done: {self._context.searches_used}
       ðŸ” Clarifications Done: {self._context.clarifications_used}
       âœ… Enough Data: {result.enough_data}
       ðŸ“ Remaining Steps: {result.remaining_steps}
       ðŸ Task Completed: {result.task_completed}
       âž¡ï¸ Next Step: {next_step}
    ###############################################"""
        )
        self.log.append(
            {
                "step_number": self._context.iteration,
                "timestamp": datetime.now().isoformat(),
                "step_type": "reasoning",
                "agent_reasoning": result.model_dump(),
            }
        )

    def _log_tool_execution(self, tool: BaseTool, result: str):
        self.logger.info(
            f"""
###############################################
ðŸ› ï¸ TOOL EXECUTION DEBUG:
    ðŸ”§ Tool Name: {tool.tool_name}
    ðŸ“‹ Tool Model: {tool.model_dump_json(indent=2)}
    ðŸ” Result: '{result[:400]}...'
###############################################"""
        )
        self.log.append(
            {
                "step_number": self._context.iteration,
                "timestamp": datetime.now().isoformat(),
                "step_type": "tool_execution",
                "tool_name": tool.tool_name,
                "agent_tool_context": tool.model_dump(),
                "agent_tool_execution_result": result,
            }
        )

    def _save_agent_log(self):
        from sgr_deep_research.core.agent_config import GlobalConfig

        logs_dir = GlobalConfig().execution.logs_dir
        os.makedirs(logs_dir, exist_ok=True)
        filepath = os.path.join(logs_dir, f"{datetime.now().strftime('%Y%m%d-%H%M%S')}-{self.id}-log.json")
        agent_log = {
            "id": self.id,
            "model_config": self.llm_config.model_dump(exclude={"api_key", "proxy"}),
            "task": self.task,
            "toolkit": [tool.tool_name for tool in self.toolkit],
            "log": self.log,
        }

        json.dump(agent_log, open(filepath, "w", encoding="utf-8"), indent=2, ensure_ascii=False)

    async def _prepare_context(self) -> list[dict]:
        """Prepare conversation context with system prompt."""
        return [
            {"role": "system", "content": PromptLoader.get_system_prompt(self.toolkit, self.prompts_config)},
            *self.conversation,
        ]

    async def _prepare_tools(self) -> list[ChatCompletionFunctionToolParam]:
        """Prepare available tools for current agent state and progress."""
        raise NotImplementedError("_prepare_tools must be implemented by subclass")

    async def _reasoning_phase(self) -> ReasoningTool:
        """Call LLM to decide next action based on current context."""
        raise NotImplementedError("_reasoning_phase must be implemented by subclass")

    async def _select_action_phase(self, reasoning: ReasoningTool) -> BaseTool:
        """Select most suitable tool for the action decided in reasoning phase.

        Returns the tool suitable for the action.
        """
        raise NotImplementedError("_select_action_phase must be implemented by subclass")

    async def _action_phase(self, tool: BaseTool) -> str:
        """Call Tool for the action decided in select_action phase.

        Returns string or dumped json result of the tool execution.
        """
        raise NotImplementedError("_action_phase must be implemented by subclass")

    async def execute(
        self,
    ):
        self.logger.info(f"ðŸš€ Starting for task: '{self.task}'")
        self.conversation.extend(
            [
                {
                    "role": "user",
                    "content": PromptLoader.get_initial_user_request(self.task, self.prompts_config),
                }
            ]
        )
        try:
            while self._context.state not in AgentStatesEnum.FINISH_STATES.value:
                self._context.iteration += 1
                self.logger.info(f"Step {self._context.iteration} started")

                reasoning = await self._reasoning_phase()
                self._context.current_step_reasoning = reasoning
                action_tool = await self._select_action_phase(reasoning)
                await self._action_phase(action_tool)

                if isinstance(action_tool, ClarificationTool):
                    self.logger.info("\nâ¸ï¸  Research paused - please answer questions")
                    self._context.state = AgentStatesEnum.WAITING_FOR_CLARIFICATION
                    self.streaming_generator.finish()
                    self._context.clarification_received.clear()
                    await self._context.clarification_received.wait()
                    continue

        except Exception as e:
            self.logger.error(f"âŒ Agent execution error: {str(e)}")
            self._context.state = AgentStatesEnum.FAILED
            traceback.print_exc()
        finally:
            if self.streaming_generator is not None:
                self.streaming_generator.finish()
            self._save_agent_log()

    def _filter_tools(self, tools: set[list[BaseTool]]) -> set[list[BaseTool]]:
        ### Filters tool set based on context state ###

        # ÐÐµÐ»ÑŒÐ·Ñ ÑƒÑ‚Ð¾Ñ‡Ð½ÑÑ‚ÑŒ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ Ð±Ð¾Ð»ÐµÐµ Ð·Ð°Ð´Ð°Ð½Ð½Ð½Ð¾Ð³Ð¾ Ñ‡Ð¸ÑÐ»Ð° Ñ€Ð°Ð·
        if self._context.clarifications_used >= self.max_clarifications:
            tools -= {
                ClarificationTool,
            }
        # ÐÐµÐ»ÑŒÐ·Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÑ‚ÑŒ Ð¿Ð¾Ð¸ÑÐº Ð² Ð˜Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ðµ  Ð±Ð¾Ð»ÐµÐµ Ð·Ð°Ð´Ð°Ð½Ð½Ð½Ð¾Ð³Ð¾ Ñ‡Ð¸ÑÐ»Ð° Ñ€Ð°Ð·
        if self._context.searches_used >= self.max_searches:
            tools -= {
                WebSearchTool,
            }
######################################################################################
        # # Ð•ÑÐ»Ð¸ Ð² Ð½Ð°Ð±Ð¾Ñ€Ðµ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² ÐµÑÑ‚ÑŒ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ,
        # #  Ñ‚Ð¾ Ð¾Ð½ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½ Ð¿ÐµÑ€Ð²Ñ‹Ð¼ Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿ÐµÑ€Ð²Ñ‹Ð¼ ÑˆÐ°Ð³Ð¾Ð¼
        if GeneratePlanTool in tools:
          if self._context.plan_generations_used == 0:
              tools = {
                  GeneratePlanTool,
              }
          else:
              tools -= {
                  GeneratePlanTool
              }
        # Ð•ÑÐ»Ð¸ Ð² Ð½Ð°Ð±Ð¾Ñ€Ðµ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² ÐµÑÑ‚ÑŒ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°,
        #  Ñ‚Ð¾ Ð¾Ð½ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½ Ð¿Ñ€ÐµÐ´Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¼ Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€ÐµÐ´Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¼ ÑˆÐ°Ð³Ð¾Ð¼,
        #  Ð° Ð·Ð° Ð½Ð¸Ð¼ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°, Ð½Ð¾ Ð½Ðµ Ñ€Ð°Ð½ÑŒÑˆÐµ
        if CreateReportTool in tools:
          if self._context.report_creations_used > 0:
              tools = {
                  FinalAnswerTool,
              }
          else:
              tools -= {
                  FinalAnswerTool,
              }

        # Ð•ÑÐ»Ð¸ Ð² Ð½Ð°Ð±Ð¾Ñ€Ðµ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² ÐµÑÑ‚ÑŒ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ Ð¿Ð¾Ð¸ÑÐºÐ° Ð² Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ðµ,
        # Ñ‚Ð¾ Ð¾Ð½ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½ Ð´Ð¾ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ† Ð¿Ð¾ Ð·Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼ Ð°Ð´Ñ€ÐµÑÐ°Ð¼,
        # Ð°Ð´Ð°Ð¿Ñ‚Ð°Ñ†Ð¸Ð¸ Ð¿Ð»Ð°Ð½Ð°, ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¸ Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
        if WebSearchTool in tools:
          if self._context.searches_used == 0:
              tools -= {
                  ExtractPageContentTool,
                  AdaptPlanTool,
                  CreateReportTool,
                  FinalAnswerTool,
              }
        # ÐÐµÐ»ÑŒÐ·Ñ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð»Ð°Ð½, Ð½Ðµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð² Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸, Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð½Ð¾Ð¹ ÑÐ¾ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹
        # (Ð”Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¸Ðµ: ÐµÑÐ»Ð¸ Ð²ÑÑ Ð½ÑƒÐ¶Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ ÑƒÐ¶Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð° Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ðµ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¸ Ð¸Ð·Ð²Ð»ÐµÐºÐ°Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ Ð½Ðµ Ð½ÑƒÐ¶Ð½Ð¾,
        # Ñ‚Ð¾ Ð¸ ÑƒÑ‚Ð¾Ñ‡Ð½ÑÑ‚ÑŒ Ð¿Ð»Ð°Ð½ Ð½Ðµ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ)
        if self._context.page_extractions_used == 0:
            tools -= {
                AdaptPlanTool,
            }
        # Ð˜Ð·Ð²Ð»ÐµÐºÐ°Ñ‚ÑŒ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ† Ð¿Ð¾ Ð·Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼ Ð°Ð´Ñ€ÐµÑÐ°Ð¼ Ð¼Ð¾Ð¶Ð½Ð¾ Ð½Ðµ Ð±Ð¾Ð»ÐµÐµ 1 Ñ€Ð°Ð·Ð° Ð½Ð° ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð°Ð´Ñ€ÐµÑÐ¾Ð² Ð² Ð˜Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ðµ
        if self._context.page_extractions_used >= self._context.searches_used:  #Ð·Ð´ÐµÑÑŒ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ ==, Ð½Ð¾ >= Ð½Ð°Ð´ÐµÐ¶Ð½ÐµÐµ
            tools -= {
                ExtractPageContentTool,
            }
        if self._context.plan_adaptations_used >= self._context.searches_used:
            tools -= {
                AdaptPlanTool,
            }
        return tools
